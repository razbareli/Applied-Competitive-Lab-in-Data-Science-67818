{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a6afe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "s=100\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (18,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "859b5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/preprocessed_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "644734ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR'])\n",
    "y = df['STAT_CAUSE_DESCR']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f09c13",
   "metadata": {},
   "source": [
    "## Baselining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54debf43",
   "metadata": {},
   "source": [
    "#### Predicting the most common train class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2562eea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            Arson       0.00      0.00      0.00       235\n",
      "         Campfire       0.00      0.00      0.00        63\n",
      "         Children       0.00      0.00      0.00        47\n",
      "   Debris Burning       0.30      0.79      0.43       358\n",
      "    Equipment Use       0.00      0.00      0.00       110\n",
      "        Fireworks       0.00      0.00      0.00        11\n",
      "        Lightning       0.53      0.72      0.61       246\n",
      "    Miscellaneous       0.38      0.34      0.36       283\n",
      "Missing/Undefined       1.00      0.19      0.32       142\n",
      "        Powerline       0.00      0.00      0.00        11\n",
      "         Railroad       0.00      0.00      0.00        18\n",
      "          Smoking       0.00      0.00      0.00        42\n",
      "        Structure       0.00      0.00      0.00         2\n",
      "\n",
      "         accuracy                           0.37      1568\n",
      "        macro avg       0.17      0.16      0.13      1568\n",
      "     weighted avg       0.31      0.37      0.29      1568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf= RandomForestClassifier(n_estimators=10, max_depth=2)\n",
    "rf.fit(X_train,y_train)\n",
    "print(classification_report(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe6a4b",
   "metadata": {},
   "source": [
    "### find best classifier for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22e50082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classifier(X_train, y_train, X_test, y_test):\n",
    "    names = [\n",
    "        \"Nearest Neighbors\",\n",
    "        \"Random Forest\",\n",
    "        \"Neural Net\",\n",
    "        \"AdaBoost\"\n",
    "    ]\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        RandomForestClassifier(),\n",
    "        MLPClassifier(alpha=1, max_iter=1000),\n",
    "        AdaBoostClassifier(),\n",
    "    ]\n",
    "\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        print(f\"Starting Classifier {names[idx]}...\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        clf.predict(X_test)\n",
    "        preds = clf.predict(X_test)\n",
    "        print(names[idx] + \" Evaluation:\")\n",
    "        print(classification_report(y_test, preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77537d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Classifier Nearest Neighbors...\n",
      "Nearest Neighbors Evaluation:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            Arson       0.29      0.47      0.36       235\n",
      "         Campfire       0.08      0.08      0.08        63\n",
      "         Children       0.05      0.06      0.06        47\n",
      "   Debris Burning       0.38      0.44      0.41       358\n",
      "    Equipment Use       0.14      0.12      0.13       110\n",
      "        Fireworks       0.20      0.09      0.13        11\n",
      "        Lightning       0.65      0.64      0.64       246\n",
      "    Miscellaneous       0.41      0.24      0.30       283\n",
      "Missing/Undefined       0.84      0.73      0.78       142\n",
      "        Powerline       0.00      0.00      0.00        11\n",
      "         Railroad       0.30      0.17      0.21        18\n",
      "          Smoking       0.00      0.00      0.00        42\n",
      "        Structure       0.00      0.00      0.00         2\n",
      "\n",
      "         accuracy                           0.40      1568\n",
      "        macro avg       0.26      0.23      0.24      1568\n",
      "     weighted avg       0.40      0.40      0.39      1568\n",
      "\n",
      "Starting Classifier Random Forest...\n",
      "Random Forest Evaluation:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            Arson       0.42      0.39      0.40       235\n",
      "         Campfire       0.32      0.10      0.15        63\n",
      "         Children       0.10      0.02      0.04        47\n",
      "   Debris Burning       0.43      0.65      0.51       358\n",
      "    Equipment Use       0.33      0.11      0.16       110\n",
      "        Fireworks       0.67      0.18      0.29        11\n",
      "        Lightning       0.62      0.79      0.70       246\n",
      "    Miscellaneous       0.41      0.39      0.40       283\n",
      "Missing/Undefined       0.86      0.84      0.85       142\n",
      "        Powerline       0.00      0.00      0.00        11\n",
      "         Railroad       0.24      0.22      0.23        18\n",
      "          Smoking       0.00      0.00      0.00        42\n",
      "        Structure       0.00      0.00      0.00         2\n",
      "\n",
      "         accuracy                           0.49      1568\n",
      "        macro avg       0.34      0.28      0.29      1568\n",
      "     weighted avg       0.46      0.49      0.46      1568\n",
      "\n",
      "Starting Classifier Neural Net...\n",
      "Neural Net Evaluation:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            Arson       0.41      0.35      0.38       235\n",
      "         Campfire       0.04      0.02      0.02        63\n",
      "         Children       0.08      0.02      0.03        47\n",
      "   Debris Burning       0.43      0.64      0.51       358\n",
      "    Equipment Use       0.25      0.13      0.17       110\n",
      "        Fireworks       0.67      0.36      0.47        11\n",
      "        Lightning       0.66      0.78      0.72       246\n",
      "    Miscellaneous       0.41      0.39      0.40       283\n",
      "Missing/Undefined       0.76      0.82      0.79       142\n",
      "        Powerline       0.00      0.00      0.00        11\n",
      "         Railroad       0.20      0.11      0.14        18\n",
      "          Smoking       0.00      0.00      0.00        42\n",
      "        Structure       0.00      0.00      0.00         2\n",
      "\n",
      "         accuracy                           0.48      1568\n",
      "        macro avg       0.30      0.28      0.28      1568\n",
      "     weighted avg       0.43      0.48      0.45      1568\n",
      "\n",
      "Starting Classifier AdaBoost...\n",
      "AdaBoost Evaluation:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            Arson       0.29      0.09      0.14       235\n",
      "         Campfire       0.00      0.00      0.00        63\n",
      "         Children       0.00      0.00      0.00        47\n",
      "   Debris Burning       0.31      0.81      0.45       358\n",
      "    Equipment Use       0.12      0.03      0.04       110\n",
      "        Fireworks       0.44      0.36      0.40        11\n",
      "        Lightning       0.40      0.71      0.51       246\n",
      "    Miscellaneous       0.20      0.03      0.05       283\n",
      "Missing/Undefined       0.00      0.00      0.00       142\n",
      "        Powerline       0.00      0.00      0.00        11\n",
      "         Railroad       0.00      0.00      0.00        18\n",
      "          Smoking       0.00      0.00      0.00        42\n",
      "        Structure       0.20      0.50      0.29         2\n",
      "\n",
      "         accuracy                           0.32      1568\n",
      "        macro avg       0.15      0.19      0.14      1568\n",
      "     weighted avg       0.22      0.32      0.22      1568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84fd19",
   "metadata": {},
   "source": [
    "# Find best parameters using random search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "100f2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_search_parameters():\n",
    "\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = np.linspace(10, 100, num = 5,dtype=int).tolist() + [None]\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 4,8, 20,40]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [2,4, 10,20]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap,\n",
    "                   'random_state': [666]}\n",
    "    return random_grid\n",
    "\n",
    "def parameter_search_classifier(X_train, y_train):\n",
    "    random_grid = get_random_search_parameters()\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2,\n",
    "                                   random_state=666, n_jobs=-1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "\n",
    "    best_params = rf_random.best_params_\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afadcd",
   "metadata": {},
   "source": [
    "# trying models with cross validation and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48892d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try neural network\n",
    "\n",
    "# try alpha = 1e-5, 1e-4, ..., 1e-1\n",
    "# try hidden_layer_sizes in [100], [100, 100], [100, 100, 100], [100, 100, 100, 100], [1000], [1000, 100]\n",
    "def try_mlp(X, y, n_components=None):\n",
    "    best_acc = 0\n",
    "    best_h = None\n",
    "    best_alpha = None\n",
    "    for h in [[100], [100, 100], [100, 100, 100], [100, 100, 100, 100], [1000], [1000, 100]]:\n",
    "        for alpha in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "            accs = []\n",
    "            kf = KFold(n_splits=2)\n",
    "            for i, (train_index, test_index) in enumerate(kf.split(X)):  # k fold cross validation\n",
    "                X_train = X[train_index]\n",
    "                y_train = y[train_index]\n",
    "                X_test = X[test_index]\n",
    "                y_test = y[test_index]\n",
    "                if n_components:  # if we use dimensionality reduction\n",
    "                    pca = PCA(n_components)\n",
    "                    pca.fit(X_train)\n",
    "                    X_train = pca.transform(X_train)\n",
    "                    X_test = pca.transform(X_test)\n",
    "                    \n",
    "                mlp = MLPClassifier(h, alpha=alpha)\n",
    "                mlp.fit(X_train, y_train)\n",
    "                acc = (mlp.predict(X_test) == y_test).sum() / len(y_test)\n",
    "                accs.append(acc)\n",
    "            mean_acc = np.mean(accs)\n",
    "            if mean_acc > best_acc:\n",
    "                print(f\"got mean acc: {mean_acc} with h={h} and alpha={alpha}, when PCA = {n_components is None}\")\n",
    "                best_acc = mean_acc\n",
    "                best_h = h\n",
    "                best_alpha = alpha\n",
    "    \n",
    "    return best_acc, best_alpha, best_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d86f97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying KNN\n",
    "def try_KNN(X, y, n_components=None):\n",
    "    best_acc = 0\n",
    "    for num_neigh in [1,2,4,8,16]:\n",
    "        for metric in ['l1', 'l2', 'cosine']:\n",
    "            best_num_neigh, best_metric = 0, None\n",
    "            accs = []\n",
    "            kf = KFold(n_splits=2)\n",
    "            for i, (train_index, test_index) in enumerate(kf.split(X)):  # k fold cross validation\n",
    "                X_train = X[train_index]\n",
    "                y_train = y[train_index]\n",
    "                X_test = X[test_index]\n",
    "                y_test = y[test_index]\n",
    "\n",
    "                if n_components:  # if we use dimensionality reduction\n",
    "                    pca = PCA(n_components)\n",
    "                    pca.fit(X_train)\n",
    "                    X_train = pca.transform(X_train)\n",
    "                    X_test = pca.transform(X_test)\n",
    "\n",
    "                neigh = KNeighborsClassifier(n_neighbors=num_neigh, metric=metric)\n",
    "                neigh.fit(X_train, y_train)\n",
    "                acc = (neigh.predict(X_test) == y_test).sum() / len(y_test)\n",
    "                accs.append(acc)\n",
    "            mean_acc = np.mean(accs)\n",
    "            if mean_acc > best_acc:\n",
    "                print(f\"got mean acc: {mean_acc} with neighbors={num_neigh} and metric={metric}, when PCA = {n_components is None}\")\n",
    "                best_acc = mean_acc\n",
    "                best_num_neigh = num_neigh\n",
    "                best_metric = metric\n",
    "\n",
    "    return best_acc, best_C, best_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af5af2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying SVM\n",
    "def try_SVM(X, y, n_components=None):\n",
    "    for c in [1e-3, 1e-2, 1e-1, 1, 10]:\n",
    "        for kernel in ['linear', 'rbf']:\n",
    "            best_C, best_kernel = 0, None\n",
    "            accs = []\n",
    "            kf = KFold(n_splits=2)\n",
    "            for i, (train_index, test_index) in enumerate(kf.split(X)):  # k fold cross validation\n",
    "                X_train = X[train_index]\n",
    "                y_train = y[train_index]\n",
    "                X_test = X[test_index]\n",
    "                y_test = y[test_index]\n",
    "\n",
    "                if n_components:  # if we use dimensionality reduction\n",
    "                    pca = PCA(n_components)\n",
    "                    pca.fit(X_train)\n",
    "                    X_train = pca.transform(X_train)\n",
    "                    X_test = pca.transform(X_test)\n",
    "\n",
    "                svm = SVC(C=c, kernel=kernel,)\n",
    "                svm.fit(X_train, y_train)\n",
    "                acc = (svm.predict(X_test) == y_test).sum() / len(y_test)\n",
    "                accs.append(acc)\n",
    "            mean_acc = np.mean(accs)\n",
    "            if mean_acc > best_acc:\n",
    "                print(f\"got mean acc: {mean_acc} with C={c} and kernel={kernel}, when PCA = {n_components is None}\")\n",
    "                best_acc = mean_acc\n",
    "                best_C = c\n",
    "                best_kernel = kernel\n",
    "\n",
    "    return best_acc, best_C, best_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "550bb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try max_depth\n",
    "# try min_samples_split with max_depth=None\n",
    "def try_random_forest(X, y, n_components=None):\n",
    "    max_depth = [10, 20, 30]\n",
    "    min_samples_split =[2, 4, 6, 8, 10]\n",
    "\n",
    "    best_acc, best_depth, best_samples_split = 0, 0, 0\n",
    "    for depth in max_depth:\n",
    "        for samples_split in min_samples_split:\n",
    "            accs = []\n",
    "            kf = KFold(n_splits=2)\n",
    "            for i, (train_index, test_index) in enumerate(kf.split(X)):  # k fold cross validation\n",
    "                X_train = X[train_index]\n",
    "                y_train = y[train_index]\n",
    "                X_test = X[test_index]\n",
    "                y_test = y[test_index]\n",
    "                if n_components:  # if we use dimensionality reduction\n",
    "                    pca = PCA(n_components)\n",
    "                    pca.fit(X_train)\n",
    "                    X_train = pca.transform(X_train)\n",
    "                    X_test = pca.transform(X_test)\n",
    "                    \n",
    "                rf = RandomForestClassifier(max_depth=depth, min_samples_split=samples_split, n_jobs=-1, oob_score=True)\n",
    "                rf.fit(X_train, y_train)\n",
    "                acc = (rf.predict(X_test) == y_test).sum() / len(y_test)\n",
    "                accs.append(acc)\n",
    "            mean_acc = np.mean(accs)\n",
    "            if mean_acc > best_acc:\n",
    "                # Record the OOB error for each `n_estimators=i` setting.\n",
    "                oob_error = 1 - rf.oob_score_\n",
    "                print(f\"got mean acc: {mean_acc} with max depth={depth},OOB={oob_error}  and min samples split={samples_split} ,when PCA = {n_components is None}\")\n",
    "                best_acc = mean_acc\n",
    "                best_depth = depth\n",
    "                best_sapmles_split = samples_split\n",
    "    \n",
    "    return best_acc, best_depth, best_sapmles_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd5c6a",
   "metadata": {},
   "source": [
    "## Confusion Matrix Based Mixture of Experts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03480078",
   "metadata": {},
   "source": [
    "We will now make a confusion matrix of best classifier.\n",
    "Then perform class clustering using confusion matrix as class similarity, learn a classifier for each cluster - \n",
    "use two level classification at test time: first classify into classes,\n",
    "then use the classifier of the cluster of the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5cee865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class ConfusionMatrixMixtureOfExperts:\n",
    "    def __init__(self, initial_model, initial_model_params, distance_threshold):\n",
    "        self.initial_model = initial_model(**initial_model_params)\n",
    "        self.clusters = None\n",
    "        self.class2expert_classifier = {}\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.label2idx = {}\n",
    "        self.idx2label = {}\n",
    "        self.class2cluster = None\n",
    "        self.cluster2classes = {}\n",
    "    \n",
    "    def get_labels(self, y_train):\n",
    "        for idx, label in enumerate(set(y_train)):\n",
    "            self.idx2label[idx] = label\n",
    "            self.label2idx[label] = idx\n",
    "            \n",
    "    def compute_confusion_matrix(self, X, y):\n",
    "        kf = KFold(n_splits=2)\n",
    "        cms = []\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "            X_train = X[train_index]\n",
    "            y_train = y[train_index]\n",
    "            X_test = X[test_index]\n",
    "            y_test = y[test_index]\n",
    "            self.initial_model.fit(X_train, y_train)\n",
    "            pred = self.initial_model.predict(X_test)\n",
    "            cm = confusion_matrix(y_test, pred)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            cms.append(cm)\n",
    "        cm = np.mean(cms, axis=0)\n",
    "        return cm\n",
    "    \n",
    "    def choose_clf(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        best_clf = None\n",
    "        best_f1 = 0\n",
    "        # random forest:\n",
    "        max_depth = [10, 20, 30, 40, 50]\n",
    "        print(\"training random forest...\")\n",
    "        for depth in max_depth:\n",
    "            rf = RandomForestClassifier(max_depth=depth, n_jobs=-1)\n",
    "            rf.fit(X_train, y_train)\n",
    "            f1 = f1_score(y_test, rf.predict(X_test), average='weighted')\n",
    "            if f1 > best_f1:\n",
    "                best_clf = rf\n",
    "                best_f1 = f1\n",
    "        # logistic regression\n",
    "        print(\"training logistic regression...\")\n",
    "        for penalty in ['l2']:\n",
    "            for c in [1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "                clf = LogisticRegression(penalty=penalty, C=c)\n",
    "                clf.fit(X_train, y_train)\n",
    "                acc = f1_score(y_test, clf.predict(X_test), average='weighted')\n",
    "                if f1 > best_f1:\n",
    "                    best_clf = clf\n",
    "                    best_f1 = f1\n",
    "        \n",
    "        print(f\"best with {best_f1}\")\n",
    "        return best_clf\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.get_labels(y)\n",
    "        y = np.array(list(map(self.label2idx.get, y)))\n",
    "        self.initial_model.fit(X, y)\n",
    "        y_pred = self.initial_model.predict(X)\n",
    "        cm = confusion_matrix(y_pred, y)\n",
    "        dists = 1 - cm\n",
    "        cm = (cm + cm.transpose()) / 2\n",
    "        self.class2cluster = AgglomerativeClustering(n_clusters=None, linkage='average', distance_threshold=self.distance_threshold,\n",
    "                                                     affinity='precomputed').fit_predict(dists)\n",
    "        # self.class2cluster[i] is cluster of class i\n",
    "        for class_, cluster in enumerate(self.class2cluster):\n",
    "            classes = self.cluster2classes.get(cluster, [])\n",
    "            self.cluster2classes[cluster] = classes + [class_]\n",
    "        # self.cluster2classes[c] is classes belonging to cluster c\n",
    "        print(self.cluster2classes)\n",
    "        print(f\"found {len(set(self.class2cluster))} cluster\")\n",
    "        for cluster, classes in self.cluster2classes.items():\n",
    "            if len(classes) > 1:\n",
    "                # selecting examples with class value in clsuter\n",
    "                X_cluster = X[[y_ in classes for y_ in y]]  \n",
    "                y_cluster = y[[y_ in classes for y_ in y]]\n",
    "                # training an expert for classes\n",
    "                expert = self.choose_clf(X_cluster, y_cluster)\n",
    "                print(f\"fitting expert for cluster {cluster}\")\n",
    "                expert.fit(X_cluster, y_cluster)\n",
    "                for y_ in classes:\n",
    "                    self.class2expert_classifier[y_] = expert\n",
    "            else:\n",
    "                # the cluster contains a single class, no need for expert\n",
    "                y_ = classes[0]\n",
    "                self.class2expert_classifier[y_] = None\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred_initial = self.initial_model.predict(X)\n",
    "        y_pred_final = y_pred_initial.copy()\n",
    "        \n",
    "        for i, y_init in enumerate(y_pred_initial):\n",
    "            # getting expert for predicted class, and predicting with expert\n",
    "            expert = self.class2expert_classifier[y_init]\n",
    "            if expert is not None:\n",
    "                y = expert.predict([X[i]])[0]\n",
    "                y_pred_final[i] = y\n",
    "                \n",
    "        y_pred_final = np.array(list(map(self.idx2label.get, y_pred_final)))\n",
    "                \n",
    "        return y_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b70d7dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== starting with clustering threshold: 0.9===\n",
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n"
     ]
    },
    {
     "data": {
      "text/plain": "<__main__.ConfusionMatrixMixtureOfExperts at 0x167642fe4c0>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR'])\n",
    "y = df['STAT_CAUSE_DESCR']\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y)\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"=== starting with clustering threshold: 0.9===\")\n",
    "cmmoe = ConfusionMatrixMixtureOfExperts(RandomForestClassifier, {\"n_jobs\":-1}, distance_threshold=0.9)\n",
    "cmmoe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "883b7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.85 with score: 0.4662751085387782===\n",
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.9 with score: 0.4647967189843515===\n",
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.95 with score: 0.46166642552333725===\n",
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.97 with score: 0.46440699810337477===\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR'])\n",
    "y = df['STAT_CAUSE_DESCR']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "ros = SMOTE(random_state=0)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "for th in [0.85, 0.9, 0.95, 0.97]:\n",
    "    cmmoe = ConfusionMatrixMixtureOfExperts(RandomForestClassifier, {\"n_jobs\":-1}, distance_threshold=th)\n",
    "    cmmoe.fit(X_train, y_train)\n",
    "    preds = cmmoe.predict(X_test)\n",
    "    print(f\"=== clustering threshold: {th} with score: {f1_score(y_test, preds, average='weighted')}===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e55cdda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.85 with score: 0.45710574678790195===\n",
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.9 with score: 0.4575742626040208===\n",
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.95 with score: 0.4620447394824607===\n",
      "{12: [0], 7: [1], 11: [2], 10: [3], 9: [4], 8: [5], 3: [6], 6: [7], 5: [8], 4: [9], 1: [10], 2: [11], 0: [12]}\n",
      "found 13 cluster\n",
      "=== clustering threshold: 0.97 with score: 0.455982595159328===\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR'])\n",
    "y = df['STAT_CAUSE_DESCR']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "for th in [0.85, 0.9, 0.95, 0.97]:\n",
    "    cmmoe = ConfusionMatrixMixtureOfExperts(RandomForestClassifier, {\"n_jobs\":-1}, distance_threshold=th)\n",
    "    cmmoe.fit(X_train, y_train)\n",
    "    preds = cmmoe.predict(X_test)\n",
    "    print(f\"=== clustering threshold: {th} with score: {f1_score(y_test, preds, average='weighted')}===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}