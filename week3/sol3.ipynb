{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ex3 - Raz Bareli"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ex3.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll take only the 'safe' features we want to work with:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "df = df[['state','date','congressional_district','gun_type','participant_gender', 'n_killed']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to work with the data, we have to fill null values, and do some data engineering as we did in previous exercises, so that's what we'll do first."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "# fill null values with mode as in ex1:\n",
    "for column in df:\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# modify 'participant_gender' as in ex2\n",
    "df.loc[df['participant_gender'].str.contains('Female', regex=True) & df['participant_gender'].str.contains('Male', regex=True), ['participant_gender']] = \"Both\"\n",
    "df.loc[df['participant_gender'].str.contains('Female', regex=True), ['participant_gender']] = \"Female\"\n",
    "df.loc[df['participant_gender'].str.contains('Male', regex=True), ['participant_gender']] = \"Male\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# modify 'gun_type' as in ex2\n",
    "df['Gun']=df.gun_type.str.extract('([A-Za-z]+|[0-9][mm]+)')\n",
    "def combine_guns(x):\n",
    "    if x in [\"Handgun\",\"9mm\",\"0mm\", \"Win\",\"Spl\", \"Spr\"]:\n",
    "        return 'Handgun'\n",
    "    if x in [\"Other\", \"Unknown\"]:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'Rifle'\n",
    "df[\"Gun\"] = df[\"Gun\"].apply(lambda x:combine_guns(x))\n",
    "df['gun_type'] = df['Gun']\n",
    "df = df.drop(columns='Gun')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# modify date to year/month as in ex1\n",
    "def delete_day(x):\n",
    "    return x[:-3]\n",
    "df['date'] = df['date'].apply(delete_day)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can get to the model training part:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "df = pd.get_dummies(df, columns=['state', 'date', 'gun_type', 'participant_gender'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['n_killed'])\n",
    "y = df['n_killed']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll choose 2 models:\n",
    "1. Linear Regression\n",
    "2. Random Forest\n",
    "\n",
    "Both are Regression models since we are trying to predict an integer between 0 and inf.\n",
    "We could, technically,  have taken a multiclass classifier in that case, but I don't think that it suits here\n",
    "since there are hierarchies between the classes. That is, 10 killed are much more than 2 killed.\n",
    "So that's why I've picked regression models.\n",
    "\n",
    "For the metric I'll choose the MSE metric.\n",
    "The advantage of MSE is that it gives different weights to large errors and small errors.\n",
    "That is, a larger error in our prediction (say, we predicted 100 instead of 1) will increase the MSE more that a smaller\n",
    "prediction error (if we predicted 2 instead of 1).\n",
    "\n",
    "One disadvantage of this metric is that we can't really tell how many times we were wrong. For instance,\n",
    "If we predict everything wrong, say: 1 instead of 0 and 0 instead of 1, the MSE won't be large, but obviously the prediction is very bad.\n",
    "In this case, the accuracy metric would have an advantage since it would have told us that we are 100% wrong."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Linear Regression =  0.2303223268249139\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "lr_mse =  mean_squared_error(y_test, lr_y_pred)\n",
    "print(\"MSE for Linear Regression = \", lr_mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Random Forest Regression =  0.28917219718131376\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_y_pred = rfr.predict(X_test)\n",
    "rfr_mse = mean_squared_error(y_test, rfr_y_pred)\n",
    "print(\"MSE for Random Forest Regression = \", rfr_mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the errors are not too large and both models performed pretty much the same, when comparing with the MSE metric.\n",
    "However, I think that since most of the n_killed data is either 0 or 1, most of the predictions are in that area as well,\n",
    "And as I explained before, it's hard to tell just based of one metric if the predictions were good, since they can all be wrong\n",
    "in the worst case, and still get a relatively low MSE."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this question I'll continue with the Random Forest Regressor from Q1, so we can see if we can improve the model by\n",
    "hyperparameter selection.\n",
    "\n",
    "I'll use Grid Search and Random Search.\n",
    "\n",
    "I've chosen 3 hyperparameters and 2 values for each, and cv=3 in cross validation - only because otherwise it would take too\n",
    "long to run (even with these settings it can take up to 10 minutes on my PC).\n",
    "\n",
    "Ideally, I would have chosen 4 parameters as the exersice suggests, and more values for each parameter, as well as cv=5 cross validation\n",
    "which is the standard from what I understand.\n",
    "\n",
    "I've chosen the MSE score, for the same reasons I've mentioned earlier, and so I'll be able to compare it to the results in Q1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.253 total time=   0.8s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.250 total time=   0.7s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.270 total time=   0.8s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.251 total time=   8.6s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.245 total time=   8.7s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.264 total time=   8.8s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.250 total time=   0.8s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.248 total time=   0.8s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.269 total time=   0.8s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.249 total time=   9.3s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.243 total time=   9.1s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.264 total time=   8.9s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.276 total time=   1.3s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.274 total time=   1.5s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.296 total time=   1.4s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.271 total time=  14.6s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.265 total time=  13.7s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.286 total time=  14.1s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.260 total time=   1.4s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.260 total time=   1.3s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.282 total time=   1.3s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.258 total time=  14.3s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.256 total time=  14.0s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.279 total time=  13.8s\n",
      "Best parameters:  {'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Best Score:  0.25196901568886293\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "gs_rfr = RandomForestRegressor()\n",
    "params_grid = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_depth': [20, 50],\n",
    "    'min_samples_split': [5, 20],\n",
    "}\n",
    "n_combinations = np.array([len(l) for key, l in params_grid.items()]).prod() # to use in random grid search\n",
    "gs = GridSearchCV(estimator=gs_rfr, param_grid=params_grid, verbose=3, cv=3, scoring=make_scorer(mean_squared_error, greater_is_better = False))\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters: ', gs.best_params_)\n",
    "print('Best Score: ', abs(gs.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END max_depth=38, min_samples_split=11, n_estimators=87;, score=-0.259 total time=  12.4s\n",
      "[CV 2/3] END max_depth=38, min_samples_split=11, n_estimators=87;, score=-0.254 total time=  12.3s\n",
      "[CV 3/3] END max_depth=38, min_samples_split=11, n_estimators=87;, score=-0.277 total time=  11.2s\n",
      "[CV 1/3] END max_depth=26, min_samples_split=12, n_estimators=99;, score=-0.251 total time=  10.7s\n",
      "[CV 2/3] END max_depth=26, min_samples_split=12, n_estimators=99;, score=-0.248 total time=  10.5s\n",
      "[CV 3/3] END max_depth=26, min_samples_split=12, n_estimators=99;, score=-0.268 total time=  10.6s\n",
      "[CV 1/3] END max_depth=22, min_samples_split=10, n_estimators=49;, score=-0.251 total time=   4.6s\n",
      "[CV 2/3] END max_depth=22, min_samples_split=10, n_estimators=49;, score=-0.247 total time=   4.7s\n",
      "[CV 3/3] END max_depth=22, min_samples_split=10, n_estimators=49;, score=-0.266 total time=   4.7s\n",
      "[CV 1/3] END max_depth=40, min_samples_split=16, n_estimators=81;, score=-0.256 total time=  13.0s\n",
      "[CV 2/3] END max_depth=40, min_samples_split=16, n_estimators=81;, score=-0.254 total time=  10.5s\n",
      "[CV 3/3] END max_depth=40, min_samples_split=16, n_estimators=81;, score=-0.276 total time=  10.3s\n",
      "[CV 1/3] END max_depth=44, min_samples_split=18, n_estimators=56;, score=-0.257 total time=   7.7s\n",
      "[CV 2/3] END max_depth=44, min_samples_split=18, n_estimators=56;, score=-0.253 total time=   7.5s\n",
      "[CV 3/3] END max_depth=44, min_samples_split=18, n_estimators=56;, score=-0.276 total time=   7.4s\n",
      "[CV 1/3] END max_depth=23, min_samples_split=6, n_estimators=40;, score=-0.254 total time=   3.9s\n",
      "[CV 2/3] END max_depth=23, min_samples_split=6, n_estimators=40;, score=-0.248 total time=   3.9s\n",
      "[CV 3/3] END max_depth=23, min_samples_split=6, n_estimators=40;, score=-0.269 total time=   4.0s\n",
      "[CV 1/3] END max_depth=49, min_samples_split=12, n_estimators=83;, score=-0.262 total time=  12.2s\n",
      "[CV 2/3] END max_depth=49, min_samples_split=12, n_estimators=83;, score=-0.258 total time=  11.6s\n",
      "[CV 3/3] END max_depth=49, min_samples_split=12, n_estimators=83;, score=-0.281 total time=  12.7s\n",
      "[CV 1/3] END max_depth=37, min_samples_split=15, n_estimators=89;, score=-0.256 total time=  10.8s\n",
      "[CV 2/3] END max_depth=37, min_samples_split=15, n_estimators=89;, score=-0.254 total time=  10.4s\n",
      "[CV 3/3] END max_depth=37, min_samples_split=15, n_estimators=89;, score=-0.274 total time=  10.3s\n",
      "Best parameters:  {'max_depth': 22, 'min_samples_split': 10, 'n_estimators': 49}\n",
      "Best Score:  0.2544453510534472\n"
     ]
    }
   ],
   "source": [
    "# Random Grid Search:\n",
    "rgs_rfr = RandomForestRegressor()\n",
    "\n",
    "ranges = {\n",
    "    'n_estimators': randint(10, 100),\n",
    "    'max_depth': randint(20, 50),\n",
    "    'min_samples_split': randint(5, 20)\n",
    "}\n",
    "rgs = RandomizedSearchCV(estimator=rgs_rfr, param_distributions=ranges, verbose=3, cv=3,  scoring=make_scorer(mean_squared_error, greater_is_better = False), n_iter=n_combinations)\n",
    "rgs.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters: ', rgs.best_params_)\n",
    "print('Best Score: ', abs(rgs.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Well, we can see that the random grid search found hyperparameters that gave better results on the test set.\n",
    "As we discussed in class - that could happen since we are not limited to the values we gave the model in the first place,\n",
    "and of course we need a bit of luck as well since choosing the parameter is randomly made.\n",
    "\n",
    "Now just for fun lets compare the new fitted models to the one from question 1:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1 forest error:  0.28917219718131376\n",
      "grid search forest error:  0.24052877578673204\n",
      "random grid search forest error:  0.2416238346794654\n"
     ]
    }
   ],
   "source": [
    "print(\"question 1 forest error: \", rfr_mse)\n",
    "print(\"grid search forest error: \", mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"random grid search forest error: \", mean_squared_error(y_test, rgs.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we can see that the hyperparamater optimization led to a better results!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q3.a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}