{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ex3 - Raz Bareli"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ex3.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll take only the features we want to work with:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "df = df[['state','date','congressional_district','gun_type','participant_gender', 'n_killed']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to work with the data, we have to fill null values, and do some data engineering as we did in previous exercises, so that's what we'll do first.\n",
    "I saw in the forum that you said it's not the essence of the exercise, but I don't see any other way to handle the data without it. So I'll do some basic\n",
    "operations just so I could train models on the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "# fill null values with mode as in ex1:\n",
    "for column in df:\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "# modify 'participant_gender' as in ex2\n",
    "df.loc[df['participant_gender'].str.contains('Female', regex=True) & df['participant_gender'].str.contains('Male', regex=True), ['participant_gender']] = \"Both\"\n",
    "df.loc[df['participant_gender'].str.contains('Female', regex=True), ['participant_gender']] = \"Female\"\n",
    "df.loc[df['participant_gender'].str.contains('Male', regex=True), ['participant_gender']] = \"Male\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "# modify 'gun_type' as in ex2\n",
    "df['Gun']=df.gun_type.str.extract('([A-Za-z]+|[0-9][mm]+)')\n",
    "def combine_guns(x):\n",
    "    if x in [\"Handgun\",\"9mm\",\"0mm\", \"Win\",\"Spl\", \"Spr\"]:\n",
    "        return 'Handgun'\n",
    "    if x in [\"Other\", \"Unknown\"]:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'Rifle'\n",
    "df[\"Gun\"] = df[\"Gun\"].apply(lambda x:combine_guns(x))\n",
    "df['gun_type'] = df['Gun']\n",
    "df = df.drop(columns='Gun')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "# modify date to year as in ex1\n",
    "def delete_day_year(x):\n",
    "    return x[:-6]\n",
    "df['date'] = df['date'].apply(delete_day_year)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can get to the model training part:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "# ive changed the names so it will be possible to un-dummie the database later on\n",
    "df.rename(columns = {'participant_gender':'gender', 'congressional_district':'district',\n",
    "                              'gun_type':'gun', 'n_killed': 'killed'}, inplace = True)\n",
    "needs_ohe = ['state', 'date', 'gun', 'gender']\n",
    "df = pd.get_dummies(df, columns=needs_ohe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['killed'])\n",
    "y = df['killed']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll choose 2 models:\n",
    "1. Linear Regression\n",
    "2. Random Forest\n",
    "\n",
    "Both are Regression models since we are trying to predict an integer between 0 and inf.\n",
    "We could, technically,  have taken a multiclass classifier in that case, but I don't think that it suits here\n",
    "since there are hierarchies between the classes. That is, 10 killed are much more than 2 killed.\n",
    "So that's why I've picked regression models.\n",
    "\n",
    "For the metric I'll choose the MSE metric.\n",
    "The advantage of MSE is that it gives different weights to large errors and small errors.\n",
    "That is, a larger error in our prediction (say, we predicted 100 instead of 1) will increase the MSE more that a smaller\n",
    "prediction error (if we predicted 2 instead of 1).\n",
    "\n",
    "One disadvantage of this metric is that we can't really tell how many times we were wrong. For instance,\n",
    "If we predict everything wrong, say: 1 instead of 0 and 0 instead of 1, the MSE won't be large, but obviously the prediction is very bad.\n",
    "In this case, the accuracy metric would have an advantage since it would have told us that we are 100% wrong."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Linear Regression =  0.24076792403292574\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "lr_mse =  mean_squared_error(y_test, lr_y_pred)\n",
    "print(\"MSE for Linear Regression = \", lr_mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Random Forest Regression =  0.2729124591049397\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_y_pred = rfr.predict(X_test)\n",
    "rfr_mse = mean_squared_error(y_test, rfr_y_pred)\n",
    "print(\"MSE for Random Forest Regression = \", rfr_mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the errors are not too large and both models performed pretty much the same, when comparing with the MSE metric.\n",
    "However, I think that since most of the n_killed data is either 0 or 1, most of the predictions are in that area as well,\n",
    "And as I explained before, it's hard to tell just based of one metric if the predictions were good, since they can all be wrong\n",
    "in the worst case, and still get a relatively low MSE."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this question I'll continue with the Random Forest Regressor from Q1, so we can see if we can improve the model by\n",
    "hyperparameter selection.\n",
    "\n",
    "I'll use Grid Search and Random Search.\n",
    "\n",
    "I've chosen 3 hyperparameters and 2 values for each, and cv=3 in cross validation - only because otherwise it would take way too\n",
    "long to run (even with these settings it can take up to 10 minutes on my PC).\n",
    "\n",
    "Ideally, I would have chosen 4 parameters as the exersice suggests, and more values for each parameter, as well as cv=5 cross validation\n",
    "which is the standard from what I understand.\n",
    "\n",
    "I've chosen the MSE score, for the same reasons I've mentioned earlier, and so I'll be able to compare it to the results in Q1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.246 total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.263 total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.257 total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.243 total time=   4.1s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.258 total time=   4.5s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.249 total time=   4.9s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.240 total time=   0.4s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.256 total time=   0.4s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.246 total time=   0.4s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.236 total time=   4.7s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.252 total time=   5.3s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.242 total time=   7.8s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.267 total time=   0.7s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.282 total time=   0.8s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.277 total time=   0.7s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.260 total time=   9.7s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.273 total time=   5.9s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.263 total time=   6.8s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.245 total time=   0.5s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.258 total time=   0.5s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.250 total time=   0.5s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.241 total time=   5.3s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.256 total time=   5.8s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.246 total time=   6.3s\n",
      "Best parameters:  {'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Best Score:  0.24320810316326988\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "gs_rfr = RandomForestRegressor()\n",
    "params_grid = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_depth': [20, 50],\n",
    "    'min_samples_split': [5, 20],\n",
    "}\n",
    "n_combinations = np.array([len(l) for key, l in params_grid.items()]).prod() # to use in random grid search\n",
    "gs = GridSearchCV(estimator=gs_rfr, param_grid=params_grid, verbose=3, cv=3, scoring=make_scorer(mean_squared_error, greater_is_better = False))\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters: ', gs.best_params_)\n",
    "print('Best Score: ', abs(gs.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END max_depth=25, min_samples_split=7, n_estimators=48;, score=-0.245 total time=   2.3s\n",
      "[CV 2/3] END max_depth=25, min_samples_split=7, n_estimators=48;, score=-0.260 total time=   2.3s\n",
      "[CV 3/3] END max_depth=25, min_samples_split=7, n_estimators=48;, score=-0.250 total time=   2.5s\n",
      "[CV 1/3] END max_depth=49, min_samples_split=5, n_estimators=19;, score=-0.263 total time=   1.0s\n",
      "[CV 2/3] END max_depth=49, min_samples_split=5, n_estimators=19;, score=-0.274 total time=   1.1s\n",
      "[CV 3/3] END max_depth=49, min_samples_split=5, n_estimators=19;, score=-0.262 total time=   1.1s\n",
      "[CV 1/3] END max_depth=21, min_samples_split=13, n_estimators=94;, score=-0.238 total time=   4.0s\n",
      "[CV 2/3] END max_depth=21, min_samples_split=13, n_estimators=94;, score=-0.253 total time=   4.1s\n",
      "[CV 3/3] END max_depth=21, min_samples_split=13, n_estimators=94;, score=-0.243 total time=   4.1s\n",
      "[CV 1/3] END max_depth=22, min_samples_split=14, n_estimators=56;, score=-0.239 total time=   2.7s\n",
      "[CV 2/3] END max_depth=22, min_samples_split=14, n_estimators=56;, score=-0.252 total time=   2.7s\n",
      "[CV 3/3] END max_depth=22, min_samples_split=14, n_estimators=56;, score=-0.245 total time=   2.7s\n",
      "[CV 1/3] END max_depth=40, min_samples_split=15, n_estimators=56;, score=-0.244 total time=   3.2s\n",
      "[CV 2/3] END max_depth=40, min_samples_split=15, n_estimators=56;, score=-0.257 total time=   3.4s\n",
      "[CV 3/3] END max_depth=40, min_samples_split=15, n_estimators=56;, score=-0.248 total time=   3.4s\n",
      "[CV 1/3] END max_depth=32, min_samples_split=18, n_estimators=63;, score=-0.240 total time=   3.3s\n",
      "[CV 2/3] END max_depth=32, min_samples_split=18, n_estimators=63;, score=-0.253 total time=   3.5s\n",
      "[CV 3/3] END max_depth=32, min_samples_split=18, n_estimators=63;, score=-0.244 total time=   3.8s\n",
      "[CV 1/3] END max_depth=37, min_samples_split=15, n_estimators=56;, score=-0.241 total time=   3.1s\n",
      "[CV 2/3] END max_depth=37, min_samples_split=15, n_estimators=56;, score=-0.256 total time=   3.2s\n",
      "[CV 3/3] END max_depth=37, min_samples_split=15, n_estimators=56;, score=-0.248 total time=   3.1s\n",
      "[CV 1/3] END max_depth=25, min_samples_split=15, n_estimators=63;, score=-0.239 total time=   3.0s\n",
      "[CV 2/3] END max_depth=25, min_samples_split=15, n_estimators=63;, score=-0.254 total time=   3.2s\n",
      "[CV 3/3] END max_depth=25, min_samples_split=15, n_estimators=63;, score=-0.244 total time=   3.2s\n",
      "Best parameters:  {'max_depth': 21, 'min_samples_split': 13, 'n_estimators': 94}\n",
      "Best Score:  0.2445016590923823\n"
     ]
    }
   ],
   "source": [
    "# Random Grid Search:\n",
    "rgs_rfr = RandomForestRegressor()\n",
    "\n",
    "ranges = {\n",
    "    'n_estimators': randint(10, 100),\n",
    "    'max_depth': randint(20, 50),\n",
    "    'min_samples_split': randint(5, 20)\n",
    "}\n",
    "rgs = RandomizedSearchCV(estimator=rgs_rfr, param_distributions=ranges, verbose=3, cv=3,  scoring=make_scorer(mean_squared_error, greater_is_better = False), n_iter=n_combinations)\n",
    "rgs.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters: ', rgs.best_params_)\n",
    "print('Best Score: ', abs(rgs.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Well, we can see that the grid search found hyperparameters that gave a bit better results on the train set, than the random grid.\n",
    "As we discussed in class - since this is random, the opposite could happen if we'll run it again,\n",
    "since we are not limited to the values we gave the model in the first place,\n",
    "and of course we need a bit of luck as well since choosing the parameter is randomly made.\n",
    "\n",
    "Now just for fun lets compare the new fitted models to the one from question 1:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1 forest error:  0.2729124591049397\n",
      "grid search forest error:  0.24302462881449252\n",
      "random grid search forest error:  0.2448067427154033\n"
     ]
    }
   ],
   "source": [
    "print(\"question 1 forest error: \", rfr_mse)\n",
    "print(\"grid search forest error: \", mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"random grid search forest error: \", mean_squared_error(y_test, rgs.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we can see that the hyperparamater optimization led to a better results!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q3.a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll use the Random Forest Regressor from previous question, with the hyperparameters we've found to perform best.\n",
    "This time well train it on all the original dataset (without cross validation).\n",
    "Please Note that since this is a random forest, without setting the seed at the beginning of the program, results can change\n",
    "between runs. So, when running the program on another PC, some statements that I've made regarding better or worse score, can change."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(max_depth=20, min_samples_split=20)"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_q3 = gs.best_estimator_\n",
    "rfr_q3.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.24293981237008988\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfr_q3.predict(X_test)\n",
    "print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll show the importance, as we learned in class:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "feature_importances = sorted(list(zip(X_train.columns, rfr_q3.feature_importances_)), key=lambda x: -x[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, in order to show the data in a bar plot, we need to combine all the \"new features\" from the one-hot-encoding process\n",
    "to their original features. That's what I'll do next:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "def most_important(data):\n",
    "    feature_importances_dict = {'state' : 0, 'gender':0, 'district':0, 'date':0, 'gun':0}\n",
    "    for i in data:\n",
    "        curr_feature = None\n",
    "        if i[0].startswith('state'):\n",
    "            curr_feature = 'state'\n",
    "        elif i[0].startswith('gender'):\n",
    "            curr_feature = 'gender'\n",
    "        elif i[0].startswith('district'):\n",
    "            curr_feature = 'district'\n",
    "        elif i[0].startswith('date'):\n",
    "            curr_feature = 'date'\n",
    "        elif i[0].startswith('gun'):\n",
    "            curr_feature = 'gun'\n",
    "        feature_importances_dict[curr_feature] += i[1]\n",
    "    return feature_importances_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "data": {
      "text/plain": "'state'"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_dict = most_important(feature_importances)\n",
    "features = list(feature_importances_dict.keys())\n",
    "importances = list(feature_importances_dict.values())\n",
    "most_important_feature = features[importances.index(max(importances))]\n",
    "least_important_feature = features[importances.index(min(importances))]\n",
    "most_important_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=features, y=importances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model without the most important feature:\n",
    "First we'll have to reverse the one hot encoding process, to eliminate the date feature (function taken from stackoverflow):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [
    "# reverse and drop state\n",
    "df_1 = undummify(df)\n",
    "df_1 = df_1.drop(columns=most_important_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "# now we'll do one hot encoding again:\n",
    "needs_ohe_1 = needs_ohe.copy()\n",
    "if most_important_feature in needs_ohe:\n",
    "    needs_ohe_1.remove(most_important_feature)\n",
    "df_1 = pd.get_dummies(df_1, columns=needs_ohe_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "X =  df_1.drop(columns='killed')\n",
    "y = df_1['killed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "rfr_1 = gs.best_estimator_\n",
    "rfr_1.fit(X_train, y_train)\n",
    "y_pred = rfr_1.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for model without most important feature =  0.2585138229776014\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE for model without most important feature = \", mean_squared_error(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we can see the MSE is a little bit higher (worse), as expected.\n",
    "As for the new important features:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances_1 = sorted(list(zip(X_train.columns, rfr_1.feature_importances_)), key=lambda x: -x[1])\n",
    "feature_importances_dict_1 = most_important(feature_importances_1)\n",
    "features_1 = list(feature_importances_dict_1.keys())\n",
    "importances_1 = list(feature_importances_dict_1.values())\n",
    "sns.barplot(x=features_1, y=importances_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll train a model with the 4 most important features, that is:\n",
    "state, district, date, gender."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "# reverse and drop state\n",
    "df_2 = undummify(df)\n",
    "df_2 = df_2.drop(columns=least_important_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [],
   "source": [
    "# now we'll do one hot encoding again:\n",
    "needs_ohe_2 = needs_ohe.copy()\n",
    "if least_important_feature in needs_ohe:\n",
    "    needs_ohe_2.remove(least_important_feature)\n",
    "df_2 = pd.get_dummies(df_2, columns=needs_ohe_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "X =  df_2.drop(columns='killed')\n",
    "y = df_2['killed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "rfr_2 = gs.best_estimator_\n",
    "rfr_2.fit(X_train, y_train)\n",
    "y_pred = rfr_2.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for model with top 4 most important features =  0.24742947979913008\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE for model with top 4 most important features = \", mean_squared_error(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The MSE improved a bit, as expected, since now we have the 4 top most important features.\n",
    "As for the new most important features:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances_2 = sorted(list(zip(X_train.columns, rfr_2.feature_importances_)), key=lambda x: -x[1])\n",
    "feature_importances_dict_2 = most_important(feature_importances_2)\n",
    "features_2 = list(feature_importances_dict_2.keys())\n",
    "importances_2 = list(feature_importances_dict_2.values())\n",
    "sns.barplot(x=features_2, y=importances_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 4\n",
    "First, a quick look of the raw data.\n",
    "It doesn't seem like there are non relevant points in the column that we are trying to predict. The percentage of\n",
    "samples that are outside the range [0 : 4] is negligible."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "data": {
      "text/plain": "0    23241\n1     6131\n2      524\n3       74\n4       22\n5        5\n6        1\n9        1\n8        1\nName: killed, dtype: int64"
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also, the other data columns are not numerical, but strings, and they have been pre-processed by me to fit the data.\n",
    "For example, I know that the only possibilities for gender are 'Male', 'Female', and 'Both'.\n",
    "So I would not expect to have big anomalies in the data at this point. For raw data it could have been a different case.\n",
    "\n",
    "I try to find some using the isolation forest we've seen in class:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [
    {
     "data": {
      "text/plain": "1    20100\ndtype: int64"
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isf = IsolationForest()\n",
    "isf.fit(X_train)\n",
    "pd.Series(isf.predict(X_train)).value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And as expected, there no apparent anomalies in the data.\n",
    "In order to answer this question more properly, I'll load a new dataset with numeric values, and\n",
    "without too much pre-processing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ex3.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "data": {
      "text/plain": "   date  longitude  latitude  n_killed  n_injured  congressional_district  \\\n0  2017  -123.8700   40.7450         0          0                     2.0   \n1  2015   -84.0148   33.9997         0          0                     7.0   \n2  2017   -77.8066   35.9934         0          0                     2.0   \n3  2016  -102.3410   31.8876         0          0                    11.0   \n4  2015   -73.4185   40.6923         1          2                     2.0   \n\n   n_guns_involved  \n0              1.0  \n1              1.0  \n2              1.0  \n3              5.0  \n4              1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>n_killed</th>\n      <th>n_injured</th>\n      <th>congressional_district</th>\n      <th>n_guns_involved</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017</td>\n      <td>-123.8700</td>\n      <td>40.7450</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015</td>\n      <td>-84.0148</td>\n      <td>33.9997</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017</td>\n      <td>-77.8066</td>\n      <td>35.9934</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016</td>\n      <td>-102.3410</td>\n      <td>31.8876</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015</td>\n      <td>-73.4185</td>\n      <td>40.6923</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['date','longitude','latitude', 'n_killed', 'n_injured', 'congressional_district','n_guns_involved']]\n",
    "for column in df:\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "def delete_day_year(x):\n",
    "    return int(x[:-6])\n",
    "df['date'] = df['date'].apply(delete_day_year)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['n_killed'])\n",
    "y = df['n_killed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "data": {
      "text/plain": " 1    16812\n-1     3288\ndtype: int64"
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isf = IsolationForest()\n",
    "isf.fit(X_train)\n",
    "pd.Series(isf.predict(X_train)).value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And that's a different result from the previous one.\n",
    "That does make sense, since we know that we have some inaccurate numbers in the latitude and longitude columns, for example.\n",
    "\n",
    "Let's try a different technique we saw in class:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "model = GLM(y,X).fit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([2.9979e+04, 1.2000e+01, 2.0000e+00, 3.0000e+00, 3.0000e+00,\n        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n array([1.04862939e-05, 1.42856026e-01, 2.85701566e-01, 4.28547106e-01,\n        5.71392646e-01, 7.14238186e-01, 8.57083725e-01, 9.99929265e-01,\n        1.14277481e+00, 1.28562034e+00, 1.42846588e+00]),\n <BarContainer object of 10 artists>)"
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.get_influence(observed=False).summary_frame()['dffits_internal'].abs(),alpha=.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This result shows that there are no anomalies in the data, or in other words - no influence points.\n",
    "That's of course, not true - and I think that the reason we can't see it in the GLM model\n",
    "is due to the fact that it's a very bad model for this data.\n",
    "And since everything is a mess - there are no points that appear unusual in the data.\n",
    "So, if we had data that can be a good fit overall for a linear model, then it would have been easier to spot\n",
    "unusual points within it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}