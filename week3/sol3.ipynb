{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ex3 - Raz Bareli"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ex3.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll take only the features we want to work with:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "df = df[['state','date','congressional_district','gun_type','participant_gender', 'n_killed']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to work with the data, we have to fill null values, and do some data engineering as we did in previous exercises, so that's what we'll do first.\n",
    "I saw in the forum that you said it's not the essence of the exercise, but I don't see any other way to handle the data without it. So I'll do some basic\n",
    "operations just so I could train models on the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# fill null values with mode as in ex1:\n",
    "for column in df:\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# modify 'participant_gender' as in ex2\n",
    "df.loc[df['participant_gender'].str.contains('Female', regex=True) & df['participant_gender'].str.contains('Male', regex=True), ['participant_gender']] = \"Both\"\n",
    "df.loc[df['participant_gender'].str.contains('Female', regex=True), ['participant_gender']] = \"Female\"\n",
    "df.loc[df['participant_gender'].str.contains('Male', regex=True), ['participant_gender']] = \"Male\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# modify 'gun_type' as in ex2\n",
    "df['Gun']=df.gun_type.str.extract('([A-Za-z]+|[0-9][mm]+)')\n",
    "def combine_guns(x):\n",
    "    if x in [\"Handgun\",\"9mm\",\"0mm\", \"Win\",\"Spl\", \"Spr\"]:\n",
    "        return 'Handgun'\n",
    "    if x in [\"Other\", \"Unknown\"]:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'Rifle'\n",
    "df[\"Gun\"] = df[\"Gun\"].apply(lambda x:combine_guns(x))\n",
    "df['gun_type'] = df['Gun']\n",
    "df = df.drop(columns='Gun')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# modify date to year/month as in ex1\n",
    "def delete_day(x):\n",
    "    return x[:-3]\n",
    "df['date'] = df['date'].apply(delete_day)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can get to the model training part:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "# ive changed the names so it will be possible to un-dummie the database later on\n",
    "df.rename(columns = {'participant_gender':'gender', 'congressional_district':'district',\n",
    "                              'gun_type':'gun', 'n_killed': 'killed'}, inplace = True)\n",
    "df = pd.get_dummies(df, columns=['state', 'date', 'gun', 'gender'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['killed'])\n",
    "y = df['killed']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll choose 2 models:\n",
    "1. Linear Regression\n",
    "2. Random Forest\n",
    "\n",
    "Both are Regression models since we are trying to predict an integer between 0 and inf.\n",
    "We could, technically,  have taken a multiclass classifier in that case, but I don't think that it suits here\n",
    "since there are hierarchies between the classes. That is, 10 killed are much more than 2 killed.\n",
    "So that's why I've picked regression models.\n",
    "\n",
    "For the metric I'll choose the MSE metric.\n",
    "The advantage of MSE is that it gives different weights to large errors and small errors.\n",
    "That is, a larger error in our prediction (say, we predicted 100 instead of 1) will increase the MSE more that a smaller\n",
    "prediction error (if we predicted 2 instead of 1).\n",
    "\n",
    "One disadvantage of this metric is that we can't really tell how many times we were wrong. For instance,\n",
    "If we predict everything wrong, say: 1 instead of 0 and 0 instead of 1, the MSE won't be large, but obviously the prediction is very bad.\n",
    "In this case, the accuracy metric would have an advantage since it would have told us that we are 100% wrong."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Linear Regression =  28120899355837.75\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "lr_mse =  mean_squared_error(y_test, lr_y_pred)\n",
    "print(\"MSE for Linear Regression = \", lr_mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Random Forest Regression =  0.2866970476488128\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_y_pred = rfr.predict(X_test)\n",
    "rfr_mse = mean_squared_error(y_test, rfr_y_pred)\n",
    "print(\"MSE for Random Forest Regression = \", rfr_mse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the errors are not too large and both models performed pretty much the same, when comparing with the MSE metric.\n",
    "However, I think that since most of the n_killed data is either 0 or 1, most of the predictions are in that area as well,\n",
    "And as I explained before, it's hard to tell just based of one metric if the predictions were good, since they can all be wrong\n",
    "in the worst case, and still get a relatively low MSE."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this question I'll continue with the Random Forest Regressor from Q1, so we can see if we can improve the model by\n",
    "hyperparameter selection.\n",
    "\n",
    "I'll use Grid Search and Random Search.\n",
    "\n",
    "I've chosen 3 hyperparameters and 2 values for each, and cv=3 in cross validation - only because otherwise it would take too\n",
    "long to run (even with these settings it can take up to 10 minutes on my PC).\n",
    "\n",
    "Ideally, I would have chosen 4 parameters as the exersice suggests, and more values for each parameter, as well as cv=5 cross validation\n",
    "which is the standard from what I understand.\n",
    "\n",
    "I've chosen the MSE score, for the same reasons I've mentioned earlier, and so I'll be able to compare it to the results in Q1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.269 total time=   1.1s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.248 total time=   1.0s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=5, n_estimators=10;, score=-0.258 total time=   1.0s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.266 total time=  12.7s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.245 total time=  10.2s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=5, n_estimators=100;, score=-0.253 total time=   9.1s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.263 total time=   1.1s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.244 total time=   1.1s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=20, n_estimators=10;, score=-0.250 total time=   0.9s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.262 total time=  10.8s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.244 total time=   9.3s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=20, n_estimators=100;, score=-0.248 total time=   8.8s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.293 total time=   1.3s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.276 total time=   1.3s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=5, n_estimators=10;, score=-0.284 total time=   1.3s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.288 total time=  13.8s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.265 total time=  15.8s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=5, n_estimators=100;, score=-0.276 total time=  19.1s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.283 total time=   2.4s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.260 total time=   2.9s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=20, n_estimators=10;, score=-0.268 total time=   2.6s\n",
      "[CV 1/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.274 total time=  23.3s\n",
      "[CV 2/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.252 total time=  20.7s\n",
      "[CV 3/3] END max_depth=50, min_samples_split=20, n_estimators=100;, score=-0.262 total time=  17.1s\n",
      "Best parameters:  {'max_depth': 20, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Best Score:  0.2512708760630587\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "gs_rfr = RandomForestRegressor()\n",
    "params_grid = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_depth': [20, 50],\n",
    "    'min_samples_split': [5, 20],\n",
    "}\n",
    "n_combinations = np.array([len(l) for key, l in params_grid.items()]).prod() # to use in random grid search\n",
    "gs = GridSearchCV(estimator=gs_rfr, param_grid=params_grid, verbose=3, cv=3, scoring=make_scorer(mean_squared_error, greater_is_better = False))\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters: ', gs.best_params_)\n",
    "print('Best Score: ', abs(gs.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END max_depth=39, min_samples_split=17, n_estimators=68;, score=-0.272 total time=  12.1s\n",
      "[CV 2/3] END max_depth=39, min_samples_split=17, n_estimators=68;, score=-0.252 total time=  12.8s\n",
      "[CV 3/3] END max_depth=39, min_samples_split=17, n_estimators=68;, score=-0.260 total time=  12.8s\n",
      "[CV 1/3] END max_depth=38, min_samples_split=13, n_estimators=83;, score=-0.275 total time=  22.4s\n",
      "[CV 2/3] END max_depth=38, min_samples_split=13, n_estimators=83;, score=-0.253 total time=  22.8s\n",
      "[CV 3/3] END max_depth=38, min_samples_split=13, n_estimators=83;, score=-0.263 total time=  21.0s\n",
      "[CV 1/3] END max_depth=47, min_samples_split=18, n_estimators=92;, score=-0.275 total time=  17.6s\n",
      "[CV 2/3] END max_depth=47, min_samples_split=18, n_estimators=92;, score=-0.253 total time=  26.1s\n",
      "[CV 3/3] END max_depth=47, min_samples_split=18, n_estimators=92;, score=-0.263 total time=  13.8s\n",
      "[CV 1/3] END max_depth=26, min_samples_split=16, n_estimators=28;, score=-0.267 total time=   3.1s\n",
      "[CV 2/3] END max_depth=26, min_samples_split=16, n_estimators=28;, score=-0.247 total time=   3.7s\n",
      "[CV 3/3] END max_depth=26, min_samples_split=16, n_estimators=28;, score=-0.252 total time=   4.8s\n",
      "[CV 1/3] END max_depth=35, min_samples_split=14, n_estimators=81;, score=-0.273 total time=  11.3s\n",
      "[CV 2/3] END max_depth=35, min_samples_split=14, n_estimators=81;, score=-0.252 total time=  12.0s\n",
      "[CV 3/3] END max_depth=35, min_samples_split=14, n_estimators=81;, score=-0.260 total time=  11.7s\n",
      "[CV 1/3] END max_depth=25, min_samples_split=18, n_estimators=94;, score=-0.265 total time=  10.3s\n",
      "[CV 2/3] END max_depth=25, min_samples_split=18, n_estimators=94;, score=-0.244 total time=   9.9s\n",
      "[CV 3/3] END max_depth=25, min_samples_split=18, n_estimators=94;, score=-0.251 total time=  10.5s\n",
      "[CV 1/3] END max_depth=44, min_samples_split=13, n_estimators=98;, score=-0.276 total time=  13.4s\n",
      "[CV 2/3] END max_depth=44, min_samples_split=13, n_estimators=98;, score=-0.255 total time=  14.9s\n",
      "[CV 3/3] END max_depth=44, min_samples_split=13, n_estimators=98;, score=-0.263 total time=  14.4s\n",
      "[CV 1/3] END max_depth=20, min_samples_split=7, n_estimators=11;, score=-0.270 total time=   1.0s\n",
      "[CV 2/3] END max_depth=20, min_samples_split=7, n_estimators=11;, score=-0.247 total time=   1.5s\n",
      "[CV 3/3] END max_depth=20, min_samples_split=7, n_estimators=11;, score=-0.255 total time=   1.4s\n",
      "Best parameters:  {'max_depth': 25, 'min_samples_split': 18, 'n_estimators': 94}\n",
      "Best Score:  0.2536886844321727\n"
     ]
    }
   ],
   "source": [
    "# Random Grid Search:\n",
    "rgs_rfr = RandomForestRegressor()\n",
    "\n",
    "ranges = {\n",
    "    'n_estimators': randint(10, 100),\n",
    "    'max_depth': randint(20, 50),\n",
    "    'min_samples_split': randint(5, 20)\n",
    "}\n",
    "rgs = RandomizedSearchCV(estimator=rgs_rfr, param_distributions=ranges, verbose=3, cv=3,  scoring=make_scorer(mean_squared_error, greater_is_better = False), n_iter=n_combinations)\n",
    "rgs.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters: ', rgs.best_params_)\n",
    "print('Best Score: ', abs(rgs.best_score_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Well, we can see that the grid search found hyperparameters that gave a bit better results on the train set, than the random grid.\n",
    "As we discussed in class - since this is random, the opposite could happen if we'll run it again,\n",
    "since we are not limited to the values we gave the model in the first place,\n",
    "and of course we need a bit of luck as well since choosing the parameter is randomly made.\n",
    "\n",
    "Now just for fun lets compare the new fitted models to the one from question 1:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1 forest error:  0.2866970476488128\n",
      "grid search forest error:  0.23834391250459477\n",
      "random grid search forest error:  0.2406516265018417\n"
     ]
    }
   ],
   "source": [
    "print(\"question 1 forest error: \", rfr_mse)\n",
    "print(\"grid search forest error: \", mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"random grid search forest error: \", mean_squared_error(y_test, rgs.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we can see that the hyperparamater optimization led to a better results!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Q3.a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll use the Random Forest Regressor from previous question, with the hyperparameters we've found to perform best.\n",
    "This time well train it on all the original dataset (without cross validation)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rfr_q3 = gs.best_estimator_\n",
    "rfr_q3.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.23926398474969832\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfr_q3.predict(X_test)\n",
    "print(\"MSE = \", mean_squared_error(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll show the importance, as we learned in class:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances = sorted(list(zip(X_train.columns, rfr_q3.feature_importances_)), key=lambda x: -x[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, in order to show the data in a bar plot, we need to combine all the \"new features\" from the one-hot-encoding process\n",
    "to their original features. That's what I'll do next:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "{'state': 0.1956680960995825,\n 'gender': 0.17514167333865377,\n 'district': 0.10865080105397927,\n 'date': 0.47705366616013595,\n 'gun_type': 0.04348576334764857}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_dict = {'state' : 0, 'gender':0, 'district':0, 'date':0, 'gun_type':0}\n",
    "for i in feature_importances:\n",
    "    curr_feature = None\n",
    "    if i[0].startswith('state'):\n",
    "        curr_feature = 'state'\n",
    "    elif i[0].startswith('gender'):\n",
    "        curr_feature = 'gender'\n",
    "    elif i[0].startswith('district'):\n",
    "        curr_feature = 'district'\n",
    "    elif i[0].startswith('date'):\n",
    "        curr_feature = 'date'\n",
    "    elif i[0].startswith('gun'):\n",
    "        curr_feature = 'gun_type'\n",
    "    feature_importances_dict[curr_feature] += i[1]\n",
    "feature_importances_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "features = list(feature_importances_dict.keys())\n",
    "importances = list(feature_importances_dict.values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=features, y=importances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model without the most important feature (date):\n",
    "First we'll have to reverse the one hot encoding process, to eliminate the date feature (function taken from stackoverflow):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reverse and drop date\n",
    "df_1 = undummify(df)\n",
    "df_1 = df_1.drop(columns='date')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# now we'll do one hot encoding again:\n",
    "df_1 = pd.get_dummies(df_1, columns=['state', 'gun', 'gender'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "X =  df_1.drop(columns='killed')\n",
    "y = df_1['killed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "3899     0\n15942    0\n17712    0\n23463    0\n17354    0\n        ..\n1859     0\n22479    1\n16156    1\n20997    0\n2236     0\nName: killed, Length: 9900, dtype: int64"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}